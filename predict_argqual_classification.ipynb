{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxschaffelder/venv/first_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>claim</th>\n",
       "      <th>argument</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>rating_initial</th>\n",
       "      <th>rating_final</th>\n",
       "      <th>persuasiveness_metric</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PQVTZECGNK3K</td>\n",
       "      <td>Governments and technology companies must do m...</td>\n",
       "      <td>It's time for governments and tech companies t...</td>\n",
       "      <td>Claude 2</td>\n",
       "      <td>Expert Writer Rhetorics</td>\n",
       "      <td>7 - Strongly support</td>\n",
       "      <td>7 - Strongly support</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3KTT9HNPV9WX</td>\n",
       "      <td>Governments and technology companies must do m...</td>\n",
       "      <td>In today's hyper-connected world, our personal...</td>\n",
       "      <td>Claude 3 Haiku</td>\n",
       "      <td>Expert Writer Rhetorics</td>\n",
       "      <td>7 - Strongly support</td>\n",
       "      <td>7 - Strongly support</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M76GMRF46C69</td>\n",
       "      <td>Cultured/lab-grown meats should be allowed to ...</td>\n",
       "      <td>The future of food must include cultured/lab-g...</td>\n",
       "      <td>Claude 2</td>\n",
       "      <td>Compelling Case</td>\n",
       "      <td>3 - Somewhat oppose</td>\n",
       "      <td>5 - Somewhat support</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3W4KKCTPTP7R</td>\n",
       "      <td>Social media companies should be required to l...</td>\n",
       "      <td>Social media companies should be required to l...</td>\n",
       "      <td>Claude 2</td>\n",
       "      <td>Compelling Case</td>\n",
       "      <td>3 - Somewhat oppose</td>\n",
       "      <td>6 - Support</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QQDKMRY3HRXJ</td>\n",
       "      <td>Employers should be allowed to monitor employe...</td>\n",
       "      <td>Allowing employers to monitor employees throug...</td>\n",
       "      <td>Claude 3 Opus</td>\n",
       "      <td>Logical Reasoning</td>\n",
       "      <td>5 - Somewhat support</td>\n",
       "      <td>5 - Somewhat support</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      worker_id                                              claim  \\\n",
       "0  PQVTZECGNK3K  Governments and technology companies must do m...   \n",
       "1  3KTT9HNPV9WX  Governments and technology companies must do m...   \n",
       "2  M76GMRF46C69  Cultured/lab-grown meats should be allowed to ...   \n",
       "3  3W4KKCTPTP7R  Social media companies should be required to l...   \n",
       "4  QQDKMRY3HRXJ  Employers should be allowed to monitor employe...   \n",
       "\n",
       "                                            argument          source  \\\n",
       "0  It's time for governments and tech companies t...        Claude 2   \n",
       "1  In today's hyper-connected world, our personal...  Claude 3 Haiku   \n",
       "2  The future of food must include cultured/lab-g...        Claude 2   \n",
       "3  Social media companies should be required to l...        Claude 2   \n",
       "4  Allowing employers to monitor employees throug...   Claude 3 Opus   \n",
       "\n",
       "               prompt_type        rating_initial          rating_final  \\\n",
       "0  Expert Writer Rhetorics  7 - Strongly support  7 - Strongly support   \n",
       "1  Expert Writer Rhetorics  7 - Strongly support  7 - Strongly support   \n",
       "2          Compelling Case   3 - Somewhat oppose  5 - Somewhat support   \n",
       "3          Compelling Case   3 - Somewhat oppose           6 - Support   \n",
       "4        Logical Reasoning  5 - Somewhat support  5 - Somewhat support   \n",
       "\n",
       "   persuasiveness_metric  predictions  \n",
       "0                      0            2  \n",
       "1                      0            2  \n",
       "2                      2            2  \n",
       "3                      3            2  \n",
       "4                      0            2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"Models/roberta_classifier.pth\"\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Ensure the model is on the correct device\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "\n",
    "# Custom dataset class for inference\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"Data/persuasion_data.csv\")  \n",
    "arguments = df[\"argument\"].tolist()\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Create dataset and dataloader for inference\n",
    "max_len_tokenizer = 512\n",
    "inference_dataset = CustomDataset(arguments, tokenizer, max_len_tokenizer)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Make predictions\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in inference_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        preds = preds + 1  # Convert predictions to 1, 2, 3\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "# Add predictions to DataFrame\n",
    "df[\"predictions\"] = predictions\n",
    "\n",
    "# Save the DataFrame with predictions\n",
    "#output_path = \"Data/arguments_to_annotate_preds_classification.csv\"\n",
    "#output_path = \"Data/persuasion_data_preds_classification.csv\"\n",
    "#df.to_csv(output_path, index=False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0       2\n",
       "1       2\n",
       "2       2\n",
       "3       2\n",
       "4       2\n",
       "       ..\n",
       "3934    2\n",
       "3935    2\n",
       "3936    2\n",
       "3937    2\n",
       "3938    2\n",
       "Name: predictions, Length: 3939, dtype: int64>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"predictions\"].value_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
